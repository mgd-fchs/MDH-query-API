{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa42d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import parser\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2558066c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from api_utils import *\n",
    "import apple_health as AppleHealth\n",
    "import health_connect as HealthConnect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a90f1",
   "metadata": {},
   "source": [
    "Select whether to query the pilot study conducted in English for CAS participants or the main study in German:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de72d97",
   "metadata": {},
   "source": [
    "## Specify project for export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d78cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT = 'PILOT_EN'\n",
    "PROJECT = \"MAIN_DE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6318f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Read environment variables\n",
    "private_key_path = os.getenv('RKS_PRIVATE_KEY_PATH')\n",
    "service_account_name = os.getenv('RKS_SERVICE_ACCOUNT')\n",
    "if PROJECT == 'PILOT_EN':\n",
    "    project_id = os.getenv('RKS_PROJECT_ID_CAS')\n",
    "else: \n",
    "    project_id = os.getenv('RKS_PROJECT_ID')\n",
    "base_url = os.getenv('BASE_URL')\n",
    "token_url = f'{base_url}/identityserver/connect/token'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2965439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = get_service_access_token(service_account_name, token_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1301a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = get_participant_ids(access_token, base_url, project_id)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ee480",
   "metadata": {},
   "source": [
    "Check if this worked, `ids` should contain a list of all participant IDs for this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf876293",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROJECT == 'PILOT_EN':\n",
    "    segment_ids = {\n",
    "        \"iOS\": \"fd09bd40-a26b-42b3-86af-4a59cbba489a\",\n",
    "        \"Android\": \"2c3457ae-3c5b-4616-8480-e1e4ac750cdd\",\n",
    "        \"Garmin\": \"df0accf3-49ac-4436-a07c-26c2dc8a0319\",\n",
    "    }\n",
    "else: \n",
    "    segment_ids = {\n",
    "        \"iOS\": \"d06bb52f-fecb-4625-94ee-26fddbbec8d6\",\n",
    "        \"Android\": \"126ab0db-2207-47ac-afbc-f8925270c4e4\"}    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f359e92",
   "metadata": {},
   "source": [
    "## Specify data for export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53235f4",
   "metadata": {},
   "source": [
    "Specify in the `data_specs` dictionary what kind of data and what data range you want to export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f803d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_specs = {\n",
    "    \"dates\": [\"2025-10-07\", \"2025-11-30\"],\n",
    "    \"measurements\": [\n",
    "        \"active_calories\",\n",
    "        \"active_calories_daily\",\n",
    "        \"blood_glucose\",\n",
    "        \"blood_pressure_sys\",\n",
    "        \"blood_pressure_dia\",\n",
    "        \"body_temp\",\n",
    "        \"distance\",\n",
    "        \"distance_daily\",\n",
    "        \"exercise_segments\",\n",
    "        \"exercise_lat\",\n",
    "        \"exercise_lon\",\n",
    "        \"exercise_alt\",\n",
    "        \"exercise_hacc\",\n",
    "        \"exercise_vacc\",\n",
    "        \"exercise_laps\",\n",
    "        \"exercise_time\",\n",
    "        \"heart_rate\",\n",
    "        \"heart_rate_min\",\n",
    "        \"heart_rate_max\",\n",
    "        \"oxygen_saturation\",\n",
    "        \"respiratory_rate\",\n",
    "        \"resting_hr\",\n",
    "        \"sleep\",\n",
    "        \"steps\",\n",
    "        \"steps_daily\",\n",
    "        \"steps_hourly\",\n",
    "        \"steps_half_hourly\",\n",
    "        \"total_calories\",\n",
    "        \"total_calories_daily\",\n",
    "        \"vo2_max\",\n",
    "        \"weight\"\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334959d",
   "metadata": {},
   "source": [
    "If needed, check additionally available data types, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a13874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HC_datatypes = HealthConnect.get_all_datatypes(access_token, project_id, base_url)\n",
    "# iOS_datatypes = AppleHealth.get_all_datatypes(access_token, project_id, base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0318615",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_results = None\n",
    "android_results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af2de9a",
   "metadata": {},
   "source": [
    "## Get all AppleHealth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92aa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "iOS_ids = get_participants_in_segment(access_token, base_url, project_id, segment_ids['iOS'], page_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43276bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "iOS_ids = get_participants_in_segment(access_token, base_url, project_id, segment_ids['iOS'], page_size=500)\n",
    "\n",
    "apple_results = AppleHealth.fetch_measurements(\n",
    "    service_access_token=access_token,\n",
    "    project_id=project_id,\n",
    "    ids=iOS_ids,\n",
    "    base_url=base_url,\n",
    "    data_specs=data_specs\n",
    ")\n",
    "\n",
    "apple_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62a5e6",
   "metadata": {},
   "source": [
    "## Get all HealthConnect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff2aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "android_ids = get_participants_in_segment(access_token, base_url, project_id, segment_ids['Android'], page_size=500)\n",
    "\n",
    "print(android_ids)\n",
    "\n",
    "android_results = HealthConnect.fetch_measurements(\n",
    "    service_access_token=access_token,\n",
    "    project_id=project_id,\n",
    "    ids=android_ids,\n",
    "    base_url=base_url,\n",
    "    data_specs=data_specs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b158058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results(results, by=\"pID\", export_dir=\"./export\", data_specs=None):\n",
    "    \"\"\"\n",
    "    Export results dict to CSVs with optional date filtering.\n",
    "\n",
    "    Args:\n",
    "        results (dict): {participantID: {measurement: DataFrame}}\n",
    "        by (str): \"pID\" for one CSV per participant,\n",
    "                  \"data_type\" for one CSV per measurement type\n",
    "        export_dir (str): folder to save CSVs into\n",
    "        data_specs (dict): may contain 'dates': ['YYYY-MM-DD', 'YYYY-MM-DD']\n",
    "    \"\"\"\n",
    "    os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "    # --- Date filter setup ---\n",
    "    start_date, end_date = None, None\n",
    "    if data_specs and \"dates\" in data_specs:\n",
    "        if len(data_specs[\"dates\"]) >= 1 and data_specs[\"dates\"][0]:\n",
    "            start_date = pd.to_datetime(data_specs[\"dates\"][0]).tz_localize(\"UTC\")\n",
    "        if len(data_specs[\"dates\"]) >= 2 and data_specs[\"dates\"][1]:\n",
    "            # include full last day by adding 23:59:59\n",
    "            end_date = pd.to_datetime(data_specs[\"dates\"][1]).tz_localize(\"UTC\") + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)\n",
    "\n",
    "    def _apply_date_filter(df):\n",
    "        if \"observationDate\" not in df.columns:\n",
    "            return df\n",
    "        df[\"observationDate\"] = pd.to_datetime(df[\"observationDate\"], errors=\"coerce\", utc=True)\n",
    "        mask = pd.Series(True, index=df.index)\n",
    "        if start_date is not None:\n",
    "            mask &= df[\"observationDate\"] >= start_date\n",
    "        if end_date is not None:\n",
    "            mask &= df[\"observationDate\"] <= end_date\n",
    "        return df.loc[mask]\n",
    "\n",
    "    # --- Export logic ---\n",
    "    if by == \"pID\":\n",
    "        for pid, meas_dict in results.items():\n",
    "            df_list = []\n",
    "            for meas, df in meas_dict.items():\n",
    "                df_filtered = _apply_date_filter(df)\n",
    "                if not df_filtered.empty:\n",
    "                    df_list.append(df_filtered)\n",
    "            if not df_list:\n",
    "                continue\n",
    "            merged = pd.concat(df_list, ignore_index=True)\n",
    "            out_path = os.path.join(export_dir, f\"{pid}.csv\")\n",
    "            merged.to_csv(out_path, index=False)\n",
    "\n",
    "    elif by == \"data_type\":\n",
    "        all_by_type = {}\n",
    "        for pid, meas_dict in results.items():\n",
    "            for meas, df in meas_dict.items():\n",
    "                df_filtered = _apply_date_filter(df)\n",
    "                if df_filtered.empty:\n",
    "                    continue\n",
    "                if meas not in all_by_type:\n",
    "                    all_by_type[meas] = []\n",
    "                all_by_type[meas].append(df_filtered)\n",
    "\n",
    "        for meas, df_list in all_by_type.items():\n",
    "            merged = pd.concat(df_list, ignore_index=True)\n",
    "            out_path = os.path.join(export_dir, f\"{meas}.csv\")\n",
    "            merged.to_csv(out_path, index=False)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid value for 'by'. Use 'pID' or 'data_type'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bcd130",
   "metadata": {},
   "source": [
    "Select a type of export. You can either export all data for a participant in a separate CSV file per participant (i.e., you will have all data for a person in a single file), or you can export each type of data (steps, RHR, glucose) into a separate file containing that measurement for all participants. Use the keyword `by=pID` or `by=data_type` respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e3ddd0",
   "metadata": {},
   "source": [
    "## Export iOS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export one CSV per participant\n",
    "export_results(apple_results, by=\"pID\", export_dir=\"./export_participants/applehealth\", data_specs=data_specs)\n",
    "\n",
    "# # Export one CSV per measurement type\n",
    "export_results(apple_results, by=\"data_type\", export_dir=\"./export_datatypes/applehealth\", data_specs=data_specs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5185de",
   "metadata": {},
   "source": [
    "## Export Android Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc76ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export one CSV per participant\n",
    "export_results(android_results, by=\"pID\", export_dir=\"./export_participants/healthconnect\", data_specs=data_specs)\n",
    "\n",
    "# # Export one CSV per measurement type\n",
    "export_results(android_results, by=\"data_type\", export_dir=\"./export_datatypes/healthconnect\", data_specs=data_specs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d982ecee",
   "metadata": {},
   "source": [
    "# Check Adherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e466b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from datetime import timedelta\n",
    "\n",
    "def get_snack_completion(base_url, project_id, access_token, first_meal):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {access_token}\",\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    url = f\"{base_url}/api/v1/administration/projects/{project_id}/surveyanswers\"\n",
    "    params = {\"limit\": 200, \"surveyName\": \"log_snack_de\"}\n",
    "\n",
    "    all_answers, page_id = [], None\n",
    "\n",
    "    while True:\n",
    "        if page_id:\n",
    "            params[\"pageID\"] = page_id\n",
    "\n",
    "        r = requests.get(url, headers=headers, params=params)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Failed: {r.status_code}, {r.text[:200]}\")\n",
    "            break\n",
    "\n",
    "        data = r.json()\n",
    "        all_answers.extend(data.get(\"surveyAnswers\", []))\n",
    "        page_id = data.get(\"nextPageID\")\n",
    "        if not page_id:\n",
    "            break\n",
    "\n",
    "    print(f\"[INFO] Retrieved {len(all_answers)} raw snack answers\")\n",
    "\n",
    "    if not all_answers:\n",
    "        return pd.DataFrame(columns=[\"participantIdentifier\", \"date\", \"snacks_per_day\"])\n",
    "\n",
    "    df = pd.DataFrame(all_answers)\n",
    "\n",
    "    # Check required fields\n",
    "    if not all(col in df.columns for col in [\"participantIdentifier\", \"surveyResultID\", \"date\"]):\n",
    "        raise KeyError(\"Missing one of required columns: participantIdentifier, surveyResultID, date\")\n",
    "\n",
    "    # Drop missing\n",
    "    df = df.dropna(subset=[\"participantIdentifier\", \"surveyResultID\", \"date\"])\n",
    "\n",
    "    # Parse timestamp and extract only date (YYYY-MM-DD)\n",
    "    def extract_date(x):\n",
    "        try:\n",
    "            return parser.isoparse(x).date()\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    df[\"date\"] = df[\"date\"].apply(extract_date)\n",
    "    df = df.dropna(subset=[\"date\"])\n",
    "\n",
    "    # Merge with first_meal to get participant-specific start date\n",
    "    merged = pd.merge(df, first_meal, on=\"participantIdentifier\", how=\"left\")\n",
    "\n",
    "    # Keep only snacks within 30 days after first meal\n",
    "    merged = merged[\n",
    "        merged[\"date\"] <= (merged[\"first_meal_date\"] + pd.to_timedelta(30, unit=\"d\"))\n",
    "    ]\n",
    "\n",
    "    # Drop duplicate surveyResultIDs\n",
    "    merged_unique = merged.drop_duplicates(subset=[\"surveyResultID\"])\n",
    "\n",
    "    # Count snacks per participant per day\n",
    "    df_snack_daily = (\n",
    "        merged_unique.groupby([\"participantIdentifier\", \"date\"], as_index=False)\n",
    "        .size()\n",
    "        .rename(columns={\"size\": \"snacks_per_day\"})\n",
    "    )\n",
    "\n",
    "    print(f\"[INFO] Produced {len(df_snack_daily)} participant-day rows\")\n",
    "    return df_snack_daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "def check_and_increment_tracking(base_url, project_id, access_token, bucket):\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\", \"Accept\": \"application/json\"}\n",
    "\n",
    "    url = f\"{base_url}/api/v1/administration/projects/{project_id}/surveytasks\"\n",
    "    params = {\"limit\": 200, \"surveyName\": \"log_breakfast_de,log_lunch_de,log_dinner_de,log_snack_de\"}\n",
    "\n",
    "    all_tasks, page_id = [], None\n",
    "    while True:\n",
    "        if page_id:\n",
    "            params[\"pageID\"] = page_id\n",
    "        r = requests.get(url, headers=headers, params=params)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Failed: {r.status_code}, {r.text[:200]}\")\n",
    "            break\n",
    "        data = r.json()\n",
    "        tasks = data.get(\"surveyTasks\", [])\n",
    "        all_tasks.extend(tasks)\n",
    "        page_id = data.get(\"nextPageID\")\n",
    "        if not page_id:\n",
    "            break\n",
    "\n",
    "    print(f\"[INFO] Retrieved {len(all_tasks)} total tasks\")\n",
    "\n",
    "    if not all_tasks:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"participantIdentifier\", \"meal_completed\", \"meal_total\", \"meal_pct\",\n",
    "            \"days_2_plus_incl_snacks\", \"days_total\", \"days_2_plus_incl_snacks_pct\"\n",
    "        ])\n",
    "\n",
    "    df = pd.DataFrame(all_tasks)[[\"participantIdentifier\", \"surveyName\", \"status\", \"endDate\"]]\n",
    "\n",
    "    # Robust datetime parsing — no .dt accessor used\n",
    "    def safe_parse_date(x):\n",
    "        try:\n",
    "            return parser.parse(x).date()\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    df[\"date\"] = df[\"endDate\"].apply(safe_parse_date)\n",
    "\n",
    "    meal_names = {\"log_breakfast_de\", \"log_lunch_de\", \"log_dinner_de\"}\n",
    "\n",
    "    # ---- MEAL COUNTS ----\n",
    "    df_meals = df[df[\"surveyName\"].isin(meal_names)]\n",
    "    meal_total = df_meals.groupby(\"participantIdentifier\").size().reset_index(name=\"meal_total\")\n",
    "    meal_completed = (\n",
    "        df_meals[df_meals[\"status\"].str.lower() == \"complete\"]\n",
    "        .groupby(\"participantIdentifier\")\n",
    "        .size()\n",
    "        .reset_index(name=\"meal_completed\")\n",
    "    )\n",
    "\n",
    "    df_meal_summary = pd.merge(meal_total, meal_completed, on=\"participantIdentifier\", how=\"outer\").fillna(0)\n",
    "    df_meal_summary[\"meal_total\"] = df_meal_summary[\"meal_total\"].astype(int)\n",
    "    df_meal_summary[\"meal_completed\"] = df_meal_summary[\"meal_completed\"].astype(int)\n",
    "    df_meal_summary[\"meal_pct\"] = (\n",
    "        (df_meal_summary[\"meal_completed\"] / df_meal_summary[\"meal_total\"] * 100)\n",
    "        .round(1)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # ---- COMPLETED SURVEYS (MEAL + SNACK) ----\n",
    "    df_complete = df[df[\"status\"].str.lower() == \"complete\"]\n",
    "\n",
    "    df_day_counts = (\n",
    "        df_complete.groupby([\"participantIdentifier\", \"date\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count_per_day\")\n",
    "    )\n",
    "\n",
    "    days_2plus = (\n",
    "        df_day_counts[df_day_counts[\"count_per_day\"] >= 2]\n",
    "        .groupby(\"participantIdentifier\")\n",
    "        .size()\n",
    "        .reset_index(name=\"days_2_plus_incl_snacks\")\n",
    "    )\n",
    "\n",
    "    # ---- TOTAL DAY RANGE (first meal → +30 days or today) ----\n",
    "    today = datetime.now(timezone.utc).date()\n",
    "    df_meals_nonan = df_meals.dropna(subset=[\"date\"])\n",
    "\n",
    "    first_meal = (\n",
    "        df_meals_nonan.groupby(\"participantIdentifier\", as_index=False)[\"date\"]\n",
    "        .min()\n",
    "        .rename(columns={\"date\": \"first_meal_date\"})\n",
    "    )\n",
    "    \n",
    "    first_meal[\"days_total\"] = first_meal[\"first_meal_date\"].apply(\n",
    "        lambda d: max(0, (min(d + timedelta(days=30), today) - d).days + 1)\n",
    "    )\n",
    "\n",
    "    df_days = pd.merge(first_meal, days_2plus, on=\"participantIdentifier\", how=\"outer\").fillna(0)\n",
    "    df_days[\"days_2_plus_incl_snacks\"] = df_days[\"days_2_plus_incl_snacks\"].astype(int)\n",
    "    df_days[\"days_total\"] = df_days[\"days_total\"].astype(int)\n",
    "    df_days[\"days_2_plus_incl_snacks_pct\"] = (\n",
    "        (df_days[\"days_2_plus_incl_snacks\"] / df_days[\"days_total\"] * 100)\n",
    "        .round(1)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # ---- SNACK COUNTS ----\n",
    "    df_snacks = get_snack_completion(base_url, project_id, access_token, first_meal)\n",
    "    snacks_total = (\n",
    "        df_snacks.groupby(\"participantIdentifier\")\n",
    "        .size()\n",
    "        .reset_index(name=\"snacks_total\")\n",
    "    )\n",
    "\n",
    "    # ---- FINAL MERGE ----\n",
    "    df_final = (\n",
    "        df_meal_summary\n",
    "        .merge(snacks_total, on=\"participantIdentifier\", how=\"outer\")\n",
    "        .merge(df_days, on=\"participantIdentifier\", how=\"outer\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    df_final[\"snacks_total\"] = df_final[\"snacks_total\"].astype(int)\n",
    "\n",
    "    df_final = df_final[[\n",
    "        \"participantIdentifier\",\n",
    "        \"meal_completed\", \"meal_total\", \"meal_pct\",\n",
    "        \"snacks_total\",\n",
    "        \"days_2_plus_incl_snacks\", \"days_total\", \"days_2_plus_incl_snacks_pct\"\n",
    "    ]]\n",
    "    \n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc32442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "def check_and_increment_tracking(base_url, project_id, access_token, bucket):\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\", \"Accept\": \"application/json\"}\n",
    "\n",
    "    url = f\"{base_url}/api/v1/administration/projects/{project_id}/surveytasks\"\n",
    "    params = {\"limit\": 200, \"surveyName\": \"log_breakfast_de,log_lunch_de,log_dinner_de,log_snack_de\"}\n",
    "\n",
    "    all_tasks, page_id = [], None\n",
    "    while True:\n",
    "        if page_id:\n",
    "            params[\"pageID\"] = page_id\n",
    "        r = requests.get(url, headers=headers, params=params)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Failed: {r.status_code}, {r.text[:200]}\")\n",
    "            break\n",
    "        data = r.json()\n",
    "        tasks = data.get(\"surveyTasks\", [])\n",
    "        all_tasks.extend(tasks)\n",
    "        page_id = data.get(\"nextPageID\")\n",
    "        if not page_id:\n",
    "            break\n",
    "\n",
    "    print(f\"[INFO] Retrieved {len(all_tasks)} total tasks\")\n",
    "\n",
    "    if not all_tasks:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"participantIdentifier\", \"meal_completed\", \"meal_total\", \"meal_pct\",\n",
    "            \"days_2_plus_incl_snacks\", \"days_total\", \"days_2_plus_incl_snacks_pct\"\n",
    "        ])\n",
    "\n",
    "    df = pd.DataFrame(all_tasks)[[\"participantIdentifier\", \"surveyName\", \"status\", \"endDate\"]]\n",
    "\n",
    "    def safe_parse_date(x):\n",
    "        try:\n",
    "            return parser.parse(x).date()\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    df[\"date\"] = df[\"endDate\"].apply(safe_parse_date)\n",
    "\n",
    "    meal_names = {\"log_breakfast_de\", \"log_lunch_de\", \"log_dinner_de\"}\n",
    "\n",
    "    # ---- MEAL COUNTS (overall) ----\n",
    "    df_meals = df[df[\"surveyName\"].isin(meal_names)]\n",
    "    meal_total = df_meals.groupby(\"participantIdentifier\").size().reset_index(name=\"meal_total\")\n",
    "    meal_completed = (\n",
    "        df_meals[df_meals[\"status\"].str.lower() == \"complete\"]\n",
    "        .groupby(\"participantIdentifier\")\n",
    "        .size()\n",
    "        .reset_index(name=\"meal_completed\")\n",
    "    )\n",
    "\n",
    "    df_meal_summary = pd.merge(meal_total, meal_completed, on=\"participantIdentifier\", how=\"outer\").fillna(0)\n",
    "    df_meal_summary[\"meal_total\"] = df_meal_summary[\"meal_total\"].astype(int)\n",
    "    df_meal_summary[\"meal_completed\"] = df_meal_summary[\"meal_completed\"].astype(int)\n",
    "    df_meal_summary[\"meal_pct\"] = (\n",
    "        (df_meal_summary[\"meal_completed\"] / df_meal_summary[\"meal_total\"] * 100)\n",
    "        .round(1)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # ---- COMPLETED SURVEYS (meal + snack) ----\n",
    "    df_complete = df[df[\"status\"].str.lower() == \"complete\"]\n",
    "\n",
    "    df_day_counts = (\n",
    "        df_complete.groupby([\"participantIdentifier\", \"date\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count_per_day\")\n",
    "    )\n",
    "\n",
    "    days_2plus = (\n",
    "        df_day_counts[df_day_counts[\"count_per_day\"] >= 2]\n",
    "        .groupby(\"participantIdentifier\")\n",
    "        .size()\n",
    "        .reset_index(name=\"days_2_plus_incl_snacks\")\n",
    "    )\n",
    "\n",
    "    # ---- TOTAL DAY RANGE ----\n",
    "    today = datetime.now(timezone.utc).date()\n",
    "    df_meals_nonan = df_meals.dropna(subset=[\"date\"])\n",
    "\n",
    "    first_meal = (\n",
    "        df_meals_nonan.groupby(\"participantIdentifier\", as_index=False)[\"date\"]\n",
    "        .min()\n",
    "        .rename(columns={\"date\": \"first_meal_date\"})\n",
    "    )\n",
    "    first_meal[\"days_total\"] = first_meal[\"first_meal_date\"].apply(\n",
    "        lambda d: max(0, (min(d + timedelta(days=30), today) - d).days + 1)\n",
    "    )\n",
    "\n",
    "    # ---- LIMIT TO FIRST 30 DAYS PER PARTICIPANT ----\n",
    "    df = pd.merge(df, first_meal[[\"participantIdentifier\", \"first_meal_date\"]], on=\"participantIdentifier\", how=\"left\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"first_meal_date\"] = pd.to_datetime(df[\"first_meal_date\"])\n",
    "    df[\"date_diff\"] = (df[\"date\"] - df[\"first_meal_date\"]).dt.days\n",
    "    df = df[df[\"date_diff\"].between(0, 30)]  # keep only days 0–30\n",
    "\n",
    "    # ---- DAYS SUMMARY ----\n",
    "    df_complete = df[df[\"status\"].str.lower() == \"complete\"]\n",
    "    df_day_counts = (\n",
    "        df_complete.groupby([\"participantIdentifier\", \"date\"])\n",
    "        .size()\n",
    "        .reset_index(name=\"count_per_day\")\n",
    "    )\n",
    "    days_2plus = (\n",
    "        df_day_counts[df_day_counts[\"count_per_day\"] >= 2]\n",
    "        .groupby(\"participantIdentifier\")\n",
    "        .size()\n",
    "        .reset_index(name=\"days_2_plus_incl_snacks\")\n",
    "    )\n",
    "\n",
    "    df_days = pd.merge(first_meal, days_2plus, on=\"participantIdentifier\", how=\"outer\").fillna(0)\n",
    "    df_days[\"days_2_plus_incl_snacks\"] = df_days[\"days_2_plus_incl_snacks\"].astype(int)\n",
    "    df_days[\"days_total\"] = df_days[\"days_total\"].astype(int)\n",
    "    df_days[\"days_2_plus_incl_snacks_pct\"] = (\n",
    "        (df_days[\"days_2_plus_incl_snacks\"] / df_days[\"days_total\"] * 100)\n",
    "        .round(1)\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # ---- SNACK COUNTS ----\n",
    "    df_snacks_daily = get_snack_completion(base_url, project_id, access_token, first_meal)\n",
    "\n",
    "    # ---- MEAL COUNTS (daily) ----\n",
    "    df_meals_completed = df_meals[df_meals[\"status\"].str.lower() == \"complete\"]\n",
    "    df_meals_daily = (\n",
    "        df_meals_completed.groupby([\"participantIdentifier\", \"date\"], as_index=False)\n",
    "        .size()\n",
    "        .rename(columns={\"size\": \"meal_completed_day\"})\n",
    "    )\n",
    "\n",
    "    # ---- MERGE DAILY TABLES ----\n",
    "    df_daily = pd.merge(\n",
    "        df_meals_daily,\n",
    "        df_snacks_daily,\n",
    "        on=[\"participantIdentifier\", \"date\"],\n",
    "        how=\"outer\"\n",
    "    ).fillna(0)\n",
    "\n",
    "    df_daily[\"meal_completed_day\"] = df_daily[\"meal_completed_day\"].astype(int)\n",
    "    df_daily[\"snacks_per_day\"] = df_daily[\"snacks_per_day\"].astype(int)\n",
    "\n",
    "    # ---- OVERALL SUMMARY TABLE ----\n",
    "    snacks_total = (\n",
    "        df_snacks_daily.groupby(\"participantIdentifier\")\n",
    "        .size()\n",
    "        .reset_index(name=\"snacks_total\")\n",
    "    )\n",
    "\n",
    "    df_final = (\n",
    "        df_meal_summary\n",
    "        .merge(snacks_total, on=\"participantIdentifier\", how=\"outer\")\n",
    "        .merge(df_days, on=\"participantIdentifier\", how=\"outer\")\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    df_final[\"snacks_total\"] = df_final[\"snacks_total\"].astype(int)\n",
    "\n",
    "    df_final = df_final[[\n",
    "        \"participantIdentifier\",\n",
    "        \"meal_completed\", \"meal_total\", \"meal_pct\",\n",
    "        \"snacks_total\",\n",
    "        \"days_2_plus_incl_snacks\", \"days_total\", \"days_2_plus_incl_snacks_pct\"\n",
    "    ]]\n",
    "    \n",
    "    print(f\"[INFO] Daily meal/snack table rows: {len(df_daily)}\")\n",
    "    return df_final, df_daily\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a245dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from dateutil import parser\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "def check_and_increment_tracking(base_url, project_id, access_token, bucket):\n",
    "    headers = {\"Authorization\": f\"Bearer {access_token}\", \"Accept\": \"application/json\"}\n",
    "\n",
    "    url = f\"{base_url}/api/v1/administration/projects/{project_id}/surveytasks\"\n",
    "    params = {\"limit\": 200, \"surveyName\": \"log_breakfast_de,log_lunch_de,log_dinner_de,log_snack_de\"}\n",
    "\n",
    "    all_tasks, page_id = [], None\n",
    "    while True:\n",
    "        if page_id:\n",
    "            params[\"pageID\"] = page_id\n",
    "        r = requests.get(url, headers=headers, params=params)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Failed: {r.status_code}, {r.text[:200]}\")\n",
    "            break\n",
    "        data = r.json()\n",
    "        tasks = data.get(\"surveyTasks\", [])\n",
    "        all_tasks.extend(tasks)\n",
    "        page_id = data.get(\"nextPageID\")\n",
    "        if not page_id:\n",
    "            break\n",
    "\n",
    "    print(f\"[INFO] Retrieved {len(all_tasks)} total tasks\")\n",
    "\n",
    "    if not all_tasks:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"participantIdentifier\", \"meal_completed\", \"meal_total\", \"meal_pct\",\n",
    "            \"days_2_plus_incl_snacks\", \"days_total\", \"days_2_plus_incl_snacks_pct\"\n",
    "        ])\n",
    "\n",
    "    # ---- INITIAL CLEANING ----\n",
    "    print(pd.DataFrame(all_tasks).columns)\n",
    "    df = pd.DataFrame(all_tasks)[[\"participantIdentifier\", \"surveyName\", \"status\", \"insertedDate\"]]\n",
    "    # print(df.head(30))\n",
    "    print(f\"Task status options: {df['status'].unique()}\")\n",
    "\n",
    "    def safe_parse_date(x):\n",
    "        try:\n",
    "            return parser.parse(x).date()\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    df[\"date\"] = df[\"insertedDate\"].apply(safe_parse_date)\n",
    "\n",
    "    # ---- DETERMINE FIRST MEAL DATE ----\n",
    "    meal_names = {\"log_breakfast_de\", \"log_lunch_de\", \"log_dinner_de\"}\n",
    "    df_meals_initial = df[df[\"surveyName\"].isin(meal_names)]\n",
    "    df_meals_nonan = df_meals_initial.dropna(subset=[\"date\"])\n",
    "\n",
    "    first_meal = (\n",
    "        df_meals_nonan.groupby(\"participantIdentifier\", as_index=False)[\"date\"]\n",
    "        .min()\n",
    "        .rename(columns={\"date\": \"first_meal_date\"})\n",
    "    )\n",
    "\n",
    "    # ---- LIMIT TO FIRST 30 DAYS PER PARTICIPANT ----\n",
    "    df = pd.merge(df, first_meal, on=\"participantIdentifier\", how=\"left\")\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"first_meal_date\"] = pd.to_datetime(df[\"first_meal_date\"])\n",
    "    df[\"date_diff\"] = (df[\"date\"] - df[\"first_meal_date\"]).dt.days\n",
    "    df = df[df[\"date_diff\"].between(0, 30)]  # inclusive: first + 29 = 30 days total\n",
    "\n",
    "    # ---- DAILY STATUS COUNTS ----\n",
    "    df_status_daily = (\n",
    "        df[df[\"status\"].isin([\"complete\", \"incomplete\", \"closed\"])]\n",
    "        .assign(status=lambda x: x[\"status\"].replace({\"closed\": \"incomplete\"}))\n",
    "        .groupby([\"participantIdentifier\", \"date\", \"status\"])\n",
    "        .size()\n",
    "        .unstack(fill_value=0)\n",
    "        .reset_index()\n",
    "        .rename(columns={\n",
    "            \"complete\": \"complete_meals\",\n",
    "            \"incomplete\": \"incomplete_meals\"\n",
    "        })\n",
    "    )\n",
    "\n",
    "    # ensure both columns exist even if one status is missing\n",
    "    for col in [\"complete_meals\", \"incomplete_meals\"]:\n",
    "        if col not in df_status_daily.columns:\n",
    "            df_status_daily[col] = 0\n",
    "\n",
    "    # print(df_status_daily.head(30))\n",
    "\n",
    "    # --- GET SNACK COUNTS PER DAY ----\n",
    "    df_snacks_daily = get_snack_completion(base_url, project_id, access_token, first_meal)\n",
    "\n",
    "    # ensure consistent datetime dtype and normalize (strip time)\n",
    "    df_status_daily[\"date\"] = pd.to_datetime(df_status_daily[\"date\"]).dt.date\n",
    "    df_snacks_daily[\"date\"] = pd.to_datetime(df_snacks_daily[\"date\"]).dt.date\n",
    "\n",
    "    # merge on both participant and date\n",
    "    df_final = (\n",
    "        df_status_daily\n",
    "        .merge(\n",
    "            df_snacks_daily,\n",
    "            on=[\"participantIdentifier\", \"date\"],\n",
    "            how=\"outer\"\n",
    "        )\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "    # ---- DAILY DERIVED COUNTS ----\n",
    "    df_final[\"meals_total_day\"] = df_final[\"complete_meals\"] + df_final[\"incomplete_meals\"]\n",
    "    df_final[\"has_2plus_complete_meals\"] = df_final[\"complete_meals\"] >= 2\n",
    "    df_final[\"has_2plus_any\"] = (df_final[\"complete_meals\"] + df_final[\"snacks_per_day\"]) >= 2\n",
    "\n",
    "    # ---- AGGREGATE PER PARTICIPANT ----\n",
    "    df_summary = (\n",
    "        df_final.groupby(\"participantIdentifier\")\n",
    "        .agg(\n",
    "            meals_completed=(\"complete_meals\", \"sum\"),\n",
    "            meals_total=(\"meals_total_day\", \"sum\"),\n",
    "            nb_days=(\"date\", \"nunique\"),\n",
    "            nb_days_2plus_meals=(\"has_2plus_complete_meals\", \"sum\"),\n",
    "            nb_days_2plus_any=(\"has_2plus_any\", \"sum\")\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # ---- DERIVED PERCENTAGES ----\n",
    "    df_summary[\"percentage_meals_tracked\"] = (\n",
    "        df_summary[\"meals_completed\"] / df_summary[\"meals_total\"] * 100\n",
    "    ).round(1)\n",
    "\n",
    "    df_summary[\"pct_days_2plus_meals\"] = (\n",
    "        df_summary[\"nb_days_2plus_meals\"] / (df_summary[\"nb_days\"]-1) * 100\n",
    "    ).round(1)\n",
    "\n",
    "    df_summary[\"pct_days_2plus_any\"] = (\n",
    "        df_summary[\"nb_days_2plus_any\"] / (df_summary[\"nb_days\"]-1) * 100\n",
    "    ).round(1)\n",
    "\n",
    "    return df_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00d4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary = check_and_increment_tracking(base_url, project_id, access_token, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f59677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a70d574",
   "metadata": {},
   "source": [
    "- `meals_completed` ... number of main meal entries completed over the duration of the study\n",
    "- `meals_total` ... total number of meal surveys delivered to the participant\n",
    "- `nb_days` ... number of days accounted for (31 includes the day of enrollment where only one sample survey is sent)\n",
    "- `nb_days_2plus_meals` ... number of days where the participant completed at least 2 main meal surveys\n",
    "- `nb_days_2plus_any` ... number of days where the participant completed at least 2 main meals OR snack entries\n",
    "- `percentage_meals_tracked` ... percentage of main meals tracked\n",
    "- `pct_days_2plus_meals` ... percentage of days on which 2+ main meals were tracked (excl. enrollment day)\n",
    "- `pct_days_2plus_any` ... percentage of days on which 2+ main meals OR snacks were tracked (excl. enrollment day) - **basis for participant payment**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
